# ğŸ”Š Noise Type Identification CNN Classifier with cepstral features (MFCC, LFCC, RFCC, HFCC):  

This repository provides a **complete pipeline** for preparing, augmenting, training, and benchmarking noise type classification models using **Mel-Frequency Cepstral Coefficients (MFCCs), Linear Frequency Cepstral Coefficients (LFCC), Rectangular Frequency Cepstral Coefficients (RFCC), Human Factor Cepstral Coefficients (RFCC)** and **Convolutional Neural Networks (CNNs)**. It includes:  

- ğŸ“‚ **Dataset structure & organization**  
- ğŸ§ **Speech data augmentation** (time-domain, spectrogram, and combination techniques)  
- âš¡ **Training with CNNs** (with/without SpecAugment)  
- ğŸ§ª **Benchmarking on test data** with detailed reports  

---

## ğŸ“‚ Dataset Folder Structure  

Datasets should be organized by **noise type** (e.g., Car, Exhibition, Station), with subfolders for **SNR levels**:  

```
dataset/
â”œâ”€â”€ Car/
â”‚ â”œâ”€â”€ 0dB/
â”‚ â”‚ â”œâ”€â”€ file1.wav
â”‚ â”‚ â””â”€â”€ ...
â”‚ â”œâ”€â”€ 5dB/
â”‚ â””â”€â”€ 10dB/
â”œâ”€â”€ Exhibition/
â”‚ â”œâ”€â”€ 0dB/
â”‚ â”œâ”€â”€ 5dB/
â”‚ â””â”€â”€ 10dB/
â””â”€â”€ Station/
â”œâ”€â”€ 0dB/
â”œâ”€â”€ 5dB/
â””â”€â”€ 10dB/
```
After augmentation (explained below), new directories are created:  
```
dataset/
â”œâ”€â”€ Car_augmented/
â”œâ”€â”€ Exhibition_augmented/
â””â”€â”€ Station_augmented/
```

---

## ğŸ§ª Experimental Hardware and Software Environment Used for this Work

| **Component**              | **Specification / Version** |
|-----------------------------|------------------------------|
| ğŸ–¥ï¸ **Operating System**        | ![Ubuntu](https://img.shields.io/badge/Ubuntu-22.04%20LTS-E95420?logo=ubuntu&logoColor=white) |
| ğŸ’» **Platform**                | Jupyter Hub |
| ğŸ® **GPU**                     | ![NVIDIA](https://img.shields.io/badge/NVIDIA-A100%2080GB%20PCIe%20Gen-76B900?logo=nvidia&logoColor=white) |
| âš™ï¸ **CPU**                     | Intel Xeon Gold 6330 (28C, 205W, 2.0GHz) |
| ğŸ§  **RAM**                     | 32 Ã— 16 = 512 GB |
| ğŸ **Python Version**          | ![Python](https://img.shields.io/badge/Python-3.10.12-3776AB?logo=python&logoColor=white) |
| ğŸ”¥ **Deep Learning Framework** | ![PyTorch](https://img.shields.io/badge/PyTorch-Latest-EE4C2C?logo=pytorch&logoColor=white) |
| ğŸ§ **Audio Library**           | ![TorchAudio](https://img.shields.io/badge/Torch%20Audio-Compatible-EE4C2C?logo=pytorch&logoColor=white) |
| ğŸ§® **Dataset Handling**        | ![NumPy](https://img.shields.io/badge/Numpy-1.x-013243?logo=numpy&logoColor=white) ![Pandas](https://img.shields.io/badge/Pandas-2.x-150458?logo=pandas&logoColor=white) |

---

### ğŸ§© Summary
This setup provides a **high-performance environment** for deep learning and speech processing tasks, featuring:
- **Ubuntu 22.04 LTS** for stability and security  
- **NVIDIA A100 (80GB)** for large-scale GPU computations  
- **Intel Xeon Gold 6330** CPUs and **512GB RAM** for parallel data processing  
- **PyTorch + TorchAudio** for model training and audio feature extraction  
- **Numpy and Pandas** for efficient dataset handling and preprocessing  

---

âœ¨ *Optimized for speech enhancement, noise classification, and real-time deep learning experiments.*

---

## ğŸ§ Speech Files Augmentation (Script: `0_speech_files_augmentation.py`)  

This script performs **data augmentation** to increase dataset diversity and robustness.  

### âœ¨ Augmentation Techniques
- **Time-Domain**: time stretching, pitch shifting, temporal shifting  
- **Spectrogram-Like**: band-stop filtering, clipping distortion  
- **Combination**: Gaussian noise overlay + pitch/time modifications  
- **Cropping & Padding**: normalize clip length to 2s  

### ğŸš€ How to Run
Update input/output dirs in the script:  
```
input_dir = "Station"          # Replace with Car, Exhibition, Station
output_dir = "Station_augmented"
```

Run:
```
0_python speech_files_augmentation.py
```
ğŸ“Š Outputs

- time_*.wav â†’ time-domain augmented
- spec_*.wav â†’ spectrogram-like augmented
- crop_*.wav â†’ cropped/padded
- combo_*.wav â†’ combined augmentations

---

## âš¡ Training (Script: 1_Noise_type_identification_X.py) (Here X = MFCC, LFCC, RFCC, HFCC)

This script trains a CNN classifier using MFCC/LFCC/RFCCHFCC-based features extracted from noisy speech samples.

ğŸš€ **Run Training**

**With SpecAugment:**
sudo /home/noise_type/noiseenv/bin/python3.10 1_Noise_type_identification_X.py --data_dir dataset --layers 6 --epochs 50 --specaugment

ğŸ“Š Training Outputs

- metrics_*.csv â†’ Training/validation metrics
- classification_view_*.csv â†’ Predictions & probabilitie
- report_*.pdf â†’ Multi-page training report (loss/accuracy, confusion matrix, ROC, calibration, PCA/t-SNE, misclassifications)
- noise_classifier_6layers_best.pth â†’ Best saved model

---

## ğŸ§ª Benchmarking (Script: 2_Noise_type_identification_X_benchmark.py)

This script evaluates a trained CNN model on a test dataset.

ğŸš€ **Run Benchmarking:**

Make sure the trained model checkpoint exists (e.g., noise_classifier_6layers_best.pth):
sudo /home/noise_type/noiseenv/bin/python3.10 2_Noise_type_identification_X_benchmark.py

ğŸ“Š **Benchmark Outputs**

- test_results.csv â†’ File-level predictions
- classification_report.csv â†’ Precision, Recall, F1 per class
- test_report.pdf â†’ Multi-page evaluation report with:
  - Test accuracy summary
  - Per-class accuracy bar chart
  - Classification report table
  - Confusion matrix
  - ROC curves & AUC
  - Calibration curves

---

ğŸ” **End-to-End Workflow**

![Workflow Diagram](/Workflow.png)
---

ğŸ“Š **Example Workflow:**

- Organize dataset (Car, Exhibition, Station with SNR subfolders)
- Augment speech files using speech_files_augmentation.py
- Train CNN using 1_Noise_type_identification_X.py
- Save model checkpoint (noise_classifier_6layers_best.pth)
- Benchmark model using 2_Noise_type_identification_X_benchmark.py
- Analyze results (CSV + PDF reports)

---
